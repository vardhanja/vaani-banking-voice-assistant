# Vaani Banking AI Backend

Complete AI-powered backend for Vaani Banking Voice Assistant using **LangGraph**, **Qwen 2.5 7B**, **LangSmith**, and **Azure TTS**.

## üéØ Features

- **Multi-Agent System**: Intent classification, banking operations, and a RAG supervisor with loan/investment/support specialists
- **LangGraph Orchestration**: Sophisticated conversation flow management
- **Local LLM**: Qwen 2.5 7B via Ollama for privacy and speed
- **Database Tools**: Safe banking operations (balance, transactions, transfers, reminders)
- **Azure TTS**: High-quality Indian voices for Hindi and English
- **LangSmith Monitoring**: Complete observability and debugging
- **Structured Logging**: Comprehensive logging for all operations
- **Error Handling**: Robust error handling with retries and fallbacks

## üìÅ Project Structure

```
ai/
‚îú‚îÄ‚îÄ main.py                 # FastAPI application
‚îú‚îÄ‚îÄ config.py               # Configuration management
‚îú‚îÄ‚îÄ requirements.txt        # Python dependencies
‚îú‚îÄ‚îÄ .env.example           # Environment variables template
‚îÇ
‚îú‚îÄ‚îÄ agents/                 # LangGraph agents
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ agent_graph.py     # Multi-agent system with routing
‚îÇ
‚îú‚îÄ‚îÄ services/              # External services
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ ollama_service.py  # Qwen 2.5 7B integration
‚îÇ   ‚îî‚îÄ‚îÄ azure_tts_service.py  # Azure Text-to-Speech
‚îÇ
‚îú‚îÄ‚îÄ tools/                 # LangChain tools
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ banking_tools.py   # Database operation tools
‚îÇ
‚îú‚îÄ‚îÄ utils/                 # Utilities
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ logging.py         # Structured logging
‚îÇ   ‚îî‚îÄ‚îÄ exceptions.py      # Custom exceptions
‚îÇ
‚îî‚îÄ‚îÄ logs/                  # Log files (auto-created)
```

## üöÄ Quick Start

### 1. Install Ollama & Download Models

```bash
# Install Ollama
brew install ollama

# Start Ollama server (in separate terminal)
ollama serve

# Download Qwen 2.5 7B (primary model - best for Hindi + English)
ollama pull qwen2.5:7b

# Download Llama 3.2 3B (fast model for voice mode)
ollama pull llama3.2:3b

# Verify models
ollama list
```

### 2. Setup Python Environment

```bash
# Navigate to ai directory
cd ai

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Configure Environment

```bash
# Copy example environment file
cp .env.example .env

# Edit .env with your settings
nano .env
```

**Required settings:**
```env
# LangSmith (get free key from smith.langchain.com)
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your_langsmith_api_key_here
LANGCHAIN_PROJECT=vaani-banking-assistant

# Ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:7b
OLLAMA_FAST_MODEL=llama3.2:3b

# Database (uses existing backend database)
DATABASE_URL=sqlite:///../backend/vaani_banking.db

# Optional: Azure TTS
AZURE_TTS_ENABLED=false
# AZURE_TTS_KEY=your_key_here
# AZURE_TTS_REGION=centralindia
```

### 4. Run the AI Backend

```bash
# Make sure Ollama is running in another terminal
# ollama serve

# Run FastAPI server
python main.py

# Or with uvicorn directly
uvicorn main:app --host 0.0.0.0 --port 8001 --reload
```

Server will start at: `http://localhost:8001`

### 5. Test the API

```bash
# Health check
curl http://localhost:8001/health

# Test chat endpoint
curl -X POST http://localhost:8001/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "What is my account balance?",
    "user_id": 1,
    "session_id": "test-session",
    "language": "en-IN",
    "user_context": {
      "account_number": "1234567890",
      "name": "Test User"
    }
  }'

# Test Hindi chat
curl -X POST http://localhost:8001/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "‡§Æ‡•á‡§∞‡§æ ‡§¨‡•à‡§≤‡•á‡§Ç‡§∏ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?",
    "user_id": 1,
    "session_id": "test-session",
    "language": "hi-IN",
    "user_context": {
      "account_number": "1234567890"
    }
  }'
```

## üì° API Endpoints

### `GET /health`
Health check endpoint.

**Response:**
```json
{
  "status": "healthy",
  "version": "1.0.0",
  "ollama_status": true,
  "azure_tts_available": false
}
```

### `POST /api/chat`
Main chat endpoint with agent orchestration.

**Request:**
```json
{
  "message": "Check my balance",
  "user_id": 1,
  "session_id": "abc123",
  "language": "en-IN",
  "user_context": {
    "account_number": "1234567890",
    "name": "John Doe"
  },
  "message_history": [
    {"role": "user", "content": "Hello"},
    {"role": "assistant", "content": "Hi! How can I help?"}
  ],
  "voice_mode": false
}
```

**Response:**
```json
{
  "success": true,
  "response": "Your account balance is ‚Çπ10,000.00.",
  "intent": "banking_operation",
  "language": "en-IN",
  "timestamp": "2025-11-17T10:30:00"
}
```

### `POST /api/chat/stream`
Streaming chat response (SSE).

Returns chunks as Server-Sent Events for real-time UI updates.

### `POST /api/tts`
Text-to-speech using Azure (optional).

**Request:**
```json
{
  "text": "Your balance is ‚Çπ10,000",
  "language": "en-IN",
  "use_azure": true
}
```

**Response:** Audio file (WAV format)

## üß† Agent System

### Agent Flow

```
User Message
    ‚Üì
Intent Classification (Llama 3.2 3B - fast)
    ‚Üì
Router (based on intent)
    ‚Üì
    ‚îú‚îÄ‚îÄ‚Üí Banking Agent (Qwen 2.5 7B + Tools)
    ‚îÇ    ‚Ä¢ get_account_balance
    ‚îÇ    ‚Ä¢ get_transaction_history
    ‚îÇ    ‚Ä¢ transfer_funds
    ‚îÇ    ‚Ä¢ get_reminders
    ‚îÇ    ‚Ä¢ set_reminder
    ‚îÇ
    ‚îî‚îÄ‚îÄ‚Üí RAG Supervisor (Qwen 2.5 7B)
      ‚Ä¢ Loan specialist (EMI, eligibility, comparisons)
      ‚Ä¢ Investment specialist (PPF, NPS, schemes)
      ‚Ä¢ Customer support specialist (general FAQs + redirection)
```

### Intents

1. **banking_operation**: Balance, transactions, transfers, reminders
2. **general_faq**: Interest rates, loans, investments, customer support (handled by RAG supervisor)
3. **loan_inquiry**: Routed via `general_faq` to the RAG loan specialist
4. **authentication**: Login, verify identity
5. **chitchat**: Greetings, out of scope (handled by deterministic greeting/feedback agents)

## üîß Available Tools

### 1. `get_account_balance`
Get current account balance.

**Usage:**
```python
{
  "account_number": "1234567890"
}
```

### 2. `get_transaction_history`
Get recent transactions.

**Usage:**
```python
{
  "account_number": "1234567890",
  "days": 30,
  "limit": 10
}
```

### 3. `transfer_funds`
Transfer money between accounts (with confirmation).

**Usage:**
```python
{
  "from_account": "1234567890",
  "to_account": "0987654321",
  "amount": 5000.0,
  "description": "Monthly rent"
}
```

### 4. `get_reminders`
Get payment reminders.

### 5. `set_reminder`
Set a new payment reminder.

## üìä LangSmith Monitoring

### Setup

1. Create account at [smith.langchain.com](https://smith.langchain.com)
2. Get API key from settings
3. Add to `.env`:
   ```env
   LANGCHAIN_API_KEY=your_key_here
   LANGCHAIN_PROJECT=vaani-banking-assistant
   ```

### What's Traced

- **Every LLM call**: Qwen responses with latency
- **Agent decisions**: Intent classification and routing
- **Tool executions**: Database operations with success/failure
- **Full conversation flows**: Complete traces from input to output

### View in LangSmith

Visit your project dashboard to see:
- Request traces with timing
- LLM token usage
- Tool call results
- Error tracking
- Performance metrics

## üé§ Voice Mode Integration

### Frontend Updates

The backend supports voice mode with fast responses:

```javascript
// frontend/src/pages/Chat.jsx
const sendMessage = async (message) => {
  const response = await fetch('http://localhost:8001/api/chat', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      message,
      user_id: session.user.id,
      session_id: sessionId,
      language: selectedLanguage,
      user_context: {
        account_number: session.user.account?.account_number,
        name: session.user.name,
      },
      message_history: messages.map(m => ({
        role: m.role,
        content: m.content
      })),
      voice_mode: isVoiceModeEnabled // Use fast model
    })
  });
  
  const data = await response.json();
  return data.response;
};
```

### Streaming for Real-time Updates

```javascript
const streamResponse = async (message) => {
  const eventSource = new EventSource(
    'http://localhost:8001/api/chat/stream?' + 
    new URLSearchParams({ message, user_id: session.user.id })
  );
  
  eventSource.onmessage = (event) => {
    if (event.data === '[DONE]') {
      eventSource.close();
    } else {
      // Append chunk to UI
      appendToMessage(event.data);
    }
  };
};
```

## üîê Security Features

### Input Validation

- Pydantic models validate all inputs
- Account number verification
- Amount limits for transfers
- SQL injection prevention (ORM)

### Error Handling

- Comprehensive try-catch blocks
- Retry logic with exponential backoff
- Graceful degradation
- Detailed error logging

### Privacy

- All LLM processing happens locally (Ollama)
- No user data sent to external services
- Session-based authentication
- Audit logging for all operations

## üìà Performance

### Benchmarks (M4 Max 128GB RAM)

| Operation | Latency | Model |
|-----------|---------|-------|
| Intent Classification | 100-200ms | Llama 3.2 3B |
| Balance Query | 500-800ms | Qwen 2.5 7B + DB |
| General FAQ | 1-2s | Qwen 2.5 7B |
| Streaming (first token) | 200-400ms | Qwen 2.5 7B |

### Optimization Tips

1. **Use Fast Model for Voice**: Set `voice_mode: true`
2. **Enable Response Caching**: Redis (optional)
3. **Limit Context Window**: Keep message history < 10 messages
4. **Parallel Tool Calls**: Future enhancement

## üêõ Troubleshooting

### Ollama Connection Error

```bash
# Check if Ollama is running
ps aux | grep ollama

# Start Ollama
ollama serve

# Verify models are downloaded
ollama list
```

### Import Errors

```bash
# Ensure virtual environment is activated
source venv/bin/activate

# Reinstall dependencies
pip install -r requirements.txt
```

### Database Errors

```bash
# Check database path in .env
# Should point to: sqlite:///../backend/vaani_banking.db

# Verify backend database exists
ls ../backend/vaani_banking.db
```

### LangSmith Not Tracing

```env
# Verify .env settings
LANGCHAIN_TRACING_V2=true  # Must be exactly this
LANGCHAIN_API_KEY=lsv2_xxx # Your actual key
LANGCHAIN_PROJECT=vaani-banking-assistant
```

## üìù Logging

Logs are written to:
- **Console**: Real-time structured logs
- **File**: `logs/ai_backend.log` (rotated at 10MB)

### Log Levels

```env
LOG_LEVEL=INFO  # INFO, DEBUG, WARNING, ERROR
```

### View Logs

```bash
# Tail logs in real-time
tail -f logs/ai_backend.log

# Search for errors
grep "ERROR" logs/ai_backend.log

# View specific agent
grep "banking_agent" logs/ai_backend.log
```

## üöÄ Next Steps

1. **Enable Azure TTS**: Get Azure key for better voice quality
2. **Add RAG System**: Implement loan document Q&A
3. **Setup Redis**: Add response caching
4. **Deploy Production**: Docker containerization
5. **Add Tests**: Unit and integration tests

## üìö Resources

- [LangGraph Docs](https://langchain-ai.github.io/langgraph/)
- [LangSmith Guide](https://docs.smith.langchain.com/)
- [Ollama Documentation](https://ollama.ai/docs)
- [Qwen 2.5 Model Card](https://huggingface.co/Qwen/Qwen2.5-7B)

## ü§ù Contributing

For development:

```bash
# Install dev dependencies
pip install pytest pytest-asyncio pytest-cov black

# Run tests
pytest

# Format code
black .
```

---

**Built with ‚ù§Ô∏è for Vaani Banking Assistant**
